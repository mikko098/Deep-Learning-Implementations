{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQlg0AI0canM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQcS1QLMPkNW"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate = 0.01, epochs = 100):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "    self.length = None\n",
        "    self.dimensions = None\n",
        "\n",
        "  def linear(self, X):\n",
        "    return torch.matmul(X, self.weights) + self.bias\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.length, self.dimensions = X.shape\n",
        "    torch.manual_seed(0)\n",
        "    self.weights = 2 * torch.rand(self.dimensions) - 1\n",
        "    self.bias = 0\n",
        "    for epoch in range(self.epochs):\n",
        "      self.update_gradient(X, y)\n",
        "      if epoch % 10 == 0:\n",
        "          loss = torch.nn.functional.binary_cross_entropy(self.predict(X), y)\n",
        "          print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "  def predict(self, X):\n",
        "    z = self.linear(X)\n",
        "    y_pred = torch.sigmoid(z)\n",
        "    return y_pred\n",
        "\n",
        "  def predict_exact(self, X, threshold):\n",
        "    z = self.linear(X)\n",
        "    y_pred = torch.sigmoid(z)\n",
        "    return (y_pred >= threshold).float()\n",
        "\n",
        "  def update_gradient(self, X, y):\n",
        "    error = self.predict(X) - y\n",
        "    self.weights -= self.learning_rate * torch.matmul(X.T, error) / self.length\n",
        "    self.bias -= self.learning_rate * torch.sum(error) / self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiAskU2vmTya"
      },
      "outputs": [],
      "source": [
        "class OneVsAllLogisticRegression:\n",
        "  def __init__(self, num_classes, learning_rate = 0.01, epochs = 100):\n",
        "    self.models = []\n",
        "    for i in range(num_classes):\n",
        "      self.models.append(LogisticRegression(learning_rate = learning_rate, epochs = epochs))\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    for i in range(len(self.models)):\n",
        "      y_encoded = (y[:,i]).float()\n",
        "      self.models[i].fit(X, y_encoded)\n",
        "\n",
        "  def predict(self, X):\n",
        "    preds = torch.stack([model.predict(X).squeeze() for model in self.models])\n",
        "    return torch.argmax(preds, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPgqLF5gN7qJ"
      },
      "outputs": [],
      "source": [
        "# upgraded version; Logistic Regression implemented by chatGPT\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.length = None\n",
        "        self.dimensions = None\n",
        "        self.loss_history = []\n",
        "\n",
        "    def linear(self, X):\n",
        "        return torch.matmul(X, self.weights) + self.bias\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Ensure inputs are tensors\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        if not isinstance(y, torch.Tensor):\n",
        "            y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "        self.length, self.dimensions = X.shape\n",
        "\n",
        "        # Initialize weights and bias\n",
        "        torch.manual_seed(0)\n",
        "        self.weights = torch.randn(self.dimensions) * 0.1  # Better initialization\n",
        "        self.bias = torch.tensor(0.0)\n",
        "\n",
        "        self.loss_history = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            self.update_gradient(X, y)\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                with torch.no_grad():\n",
        "                    predictions = self.predict(X)\n",
        "                    # Add small epsilon to prevent log(0)\n",
        "                    predictions = torch.clamp(predictions, 1e-7, 1 - 1e-7)\n",
        "                    loss = F.binary_cross_entropy(predictions, y)\n",
        "                    self.loss_history.append(loss.item())\n",
        "                    print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        z = self.linear(X)\n",
        "        y_pred = torch.sigmoid(z)\n",
        "        return y_pred\n",
        "\n",
        "    def predict_exact(self, X, threshold=0.5):\n",
        "        predictions = self.predict(X)\n",
        "        return (predictions >= threshold).float()\n",
        "\n",
        "    def update_gradient(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        error = predictions - y\n",
        "\n",
        "        # Gradient descent updates\n",
        "        self.weights -= self.learning_rate * torch.matmul(X.T, error) / self.length\n",
        "        self.bias -= self.learning_rate * torch.sum(error) / self.length\n",
        "\n",
        "\n",
        "class MultinomialLogisticRegression:\n",
        "    def __init__(self, num_classes, learning_rate=0.01, epochs=100):\n",
        "        self.num_classes = num_classes\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "        self.loss_history = []\n",
        "\n",
        "    def _one_hot_encode(self, y):\n",
        "        if len(y.shape) == 1:\n",
        "            y_encoded = torch.zeros(len(y), self.num_classes)\n",
        "            y_encoded[torch.arange(len(y)), y.long()] = 1\n",
        "            return y_encoded\n",
        "        else:\n",
        "            return y.float()\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Ensure inputs are tensors\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        if not isinstance(y, torch.Tensor):\n",
        "            y = torch.tensor(y)\n",
        "\n",
        "        # Convert to one-hot if necessary\n",
        "        y_encoded = self._one_hot_encode(y)\n",
        "\n",
        "        length, dimensions = X.shape\n",
        "\n",
        "        # Initialize weights and bias\n",
        "        torch.manual_seed(0)\n",
        "        self.weights = torch.randn(dimensions, self.num_classes) * 0.1\n",
        "        self.bias = torch.zeros(self.num_classes)\n",
        "\n",
        "        self.loss_history = []\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            self._update_gradient(X, y_encoded)\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                with torch.no_grad():\n",
        "                    predictions = self.predict_proba(X)\n",
        "                    loss = F.cross_entropy(predictions, torch.argmax(y_encoded, dim=1))\n",
        "                    self.loss_history.append(loss.item())\n",
        "                    print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    def _linear(self, X):\n",
        "        return torch.matmul(X, self.weights) + self.bias\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if not isinstance(X, torch.Tensor):\n",
        "            X = torch.tensor(X, dtype=torch.float32)\n",
        "        z = self._linear(X)\n",
        "        return F.softmax(z, dim=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probabilities = self.predict_proba(X)\n",
        "        return torch.argmax(probabilities, dim=1)\n",
        "\n",
        "    def _update_gradient(self, X, y_encoded):\n",
        "        probabilities = self.predict_proba(X)\n",
        "        error = probabilities - y_encoded\n",
        "\n",
        "        length = X.shape[0]\n",
        "\n",
        "        # Update weights and bias\n",
        "        self.weights -= self.learning_rate * torch.matmul(X.T, error) / length\n",
        "        self.bias -= self.learning_rate * torch.sum(error, dim=0) / length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuuprPLEcYOg"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF5v0FXbdqvq"
      },
      "outputs": [],
      "source": [
        "temp = df[df[\"species\"].isin([\"setosa\", \"virginica\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzd4p7U1cY1w"
      },
      "outputs": [],
      "source": [
        "X, y = temp.iloc[:,:4], temp.iloc[:,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2yBW5RFcY6p"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X.values, dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zut9LYVgcZCK"
      },
      "outputs": [],
      "source": [
        "y_encoded = torch.tensor(pd.get_dummies(y, drop_first=True).values, dtype = torch.float32).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnpSnlGGeSyj"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(learning_rate= 0.01, epochs = 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xLz9UE7f1O3",
        "outputId": "0f1d124b-9a2d-4d6e-d1fc-3f2d37933106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 2.6351\n",
            "Epoch 10, Loss: 1.9539\n",
            "Epoch 20, Loss: 1.6256\n",
            "Epoch 30, Loss: 1.4381\n",
            "Epoch 40, Loss: 1.2800\n",
            "Epoch 50, Loss: 1.1374\n",
            "Epoch 60, Loss: 1.0097\n",
            "Epoch 70, Loss: 0.8970\n",
            "Epoch 80, Loss: 0.7987\n",
            "Epoch 90, Loss: 0.7135\n",
            "Epoch 100, Loss: 0.6400\n",
            "Epoch 110, Loss: 0.5767\n",
            "Epoch 120, Loss: 0.5223\n",
            "Epoch 130, Loss: 0.4754\n",
            "Epoch 140, Loss: 0.4347\n",
            "Epoch 150, Loss: 0.3995\n",
            "Epoch 160, Loss: 0.3687\n",
            "Epoch 170, Loss: 0.3417\n",
            "Epoch 180, Loss: 0.3180\n",
            "Epoch 190, Loss: 0.2969\n",
            "Epoch 200, Loss: 0.2782\n",
            "Epoch 210, Loss: 0.2615\n",
            "Epoch 220, Loss: 0.2465\n",
            "Epoch 230, Loss: 0.2330\n",
            "Epoch 240, Loss: 0.2208\n",
            "Epoch 250, Loss: 0.2097\n",
            "Epoch 260, Loss: 0.1996\n",
            "Epoch 270, Loss: 0.1904\n",
            "Epoch 280, Loss: 0.1819\n",
            "Epoch 290, Loss: 0.1741\n",
            "Epoch 300, Loss: 0.1669\n",
            "Epoch 310, Loss: 0.1602\n",
            "Epoch 320, Loss: 0.1541\n",
            "Epoch 330, Loss: 0.1484\n",
            "Epoch 340, Loss: 0.1430\n",
            "Epoch 350, Loss: 0.1380\n",
            "Epoch 360, Loss: 0.1334\n",
            "Epoch 370, Loss: 0.1290\n",
            "Epoch 380, Loss: 0.1249\n",
            "Epoch 390, Loss: 0.1210\n",
            "Epoch 400, Loss: 0.1174\n",
            "Epoch 410, Loss: 0.1140\n",
            "Epoch 420, Loss: 0.1107\n",
            "Epoch 430, Loss: 0.1077\n",
            "Epoch 440, Loss: 0.1047\n",
            "Epoch 450, Loss: 0.1020\n",
            "Epoch 460, Loss: 0.0994\n",
            "Epoch 470, Loss: 0.0969\n",
            "Epoch 480, Loss: 0.0945\n",
            "Epoch 490, Loss: 0.0922\n"
          ]
        }
      ],
      "source": [
        "model.fit(X, y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHGPwHcobkvW"
      },
      "outputs": [],
      "source": [
        "X, y = df.iloc[:,:4], df.iloc[:,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuPuMBvrbx28"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X.values, dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "josj9vCmhwUV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X = StandardScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBdu8Mtnh1yN"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X, dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_hOQGAciRcU"
      },
      "outputs": [],
      "source": [
        "y_encoded = torch.tensor(pd.get_dummies(df.iloc[:,4]).values, dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC5F15i6aiT6"
      },
      "outputs": [],
      "source": [
        "model = MultinomialLogisticRegression(3, learning_rate= 0.01, epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw2x4jr6bghm",
        "outputId": "65f18954-e91b-492f-a877-573dbabbd31d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.1234\n",
            "Epoch 10, Loss: 1.0902\n",
            "Epoch 20, Loss: 1.0597\n",
            "Epoch 30, Loss: 1.0322\n",
            "Epoch 40, Loss: 1.0077\n",
            "Epoch 50, Loss: 0.9862\n",
            "Epoch 60, Loss: 0.9672\n",
            "Epoch 70, Loss: 0.9506\n",
            "Epoch 80, Loss: 0.9359\n",
            "Epoch 90, Loss: 0.9230\n"
          ]
        }
      ],
      "source": [
        "model.fit(X, y_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmyK7m0CORLj",
        "outputId": "7da74000-b439-4351-d6ab-effd875e39d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1,\n",
              "        2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1,\n",
              "        1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "v-1qMH-1Oq0S",
        "outputId": "9e34dd31-97c9-4d3d-9fa9-5fe48a6f988b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "145    2\n",
              "146    2\n",
              "147    2\n",
              "148    2\n",
              "149    2\n",
              "Name: species, Length: 150, dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.apply(lambda x: map[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2wbtC6TPQ09",
        "outputId": "810b0211-7626-4bc2-b816-3fee3e6aebcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADyVtu0RPY6F"
      },
      "outputs": [],
      "source": [
        "actual = torch.tensor(y.apply(lambda x: map[x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZC8big6PUUm",
        "outputId": "0e80cbf2-4eba-41ef-f0c0-3362d58b9b04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actual[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggdf1IehcG3u",
        "outputId": "52a999e7-5971-40a2-e348-3f753a468408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.8333)\n"
          ]
        }
      ],
      "source": [
        "total_sum = 0\n",
        "predictions = model.predict(X)\n",
        "print((actual == predictions).sum() / len(actual))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8NlhFbrfHEM"
      },
      "outputs": [],
      "source": [
        "map = {\"setosa\" : 0, \"virginica\" : 2, \"versicolor\" : 1 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS_0sX8Fd6yQ",
        "outputId": "b0ad91dd-07fa-44a9-f8ca-c1a313a566b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5.1000, 3.5000, 1.4000, 0.2000])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfHBnG9Bex68",
        "outputId": "bf31a7ad-8f4f-411b-bf51-92573264f510"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3nJE7TmfVaz",
        "outputId": "534bd831-1e3f-44e4-cb10-366dfc12e489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Scale features\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APknVLRZihti"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
